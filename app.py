import streamlit as st
import pickle
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import nltk

# -------------------------
# NLTK Downloads
# -------------------------
nltk.download('punkt')
nltk.download('punkt_tab')   # ‚≠ê ŸÖŸáŸÖ ÿ¨ÿØŸãÿß
nltk.download('stopwords')
nltk.download('wordnet')

# -------------------------
# Load model & vectorizer
# -------------------------
with open('logreg_model.pkl', 'rb') as f:
    model = pickle.load(f)

with open('tfidf_vectorizer.pkl', 'rb') as f:
    tfidvect = pickle.load(f)

# -------------------------
# Streamlit Page Config
# -------------------------
st.set_page_config(
    page_title="Fake News Detector",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------
# Sidebar (User Guide)
# -------------------------
st.sidebar.title("üìò How to Use")
st.sidebar.markdown("""
Welcome to the **Fake News Detection App**!  
Follow these steps:

1Ô∏è‚É£ **Enter the news source**  
Examples: *Reuters, BBC, CNN...*

2Ô∏è‚É£ **Paste the full news text**  
The more text you provide, the more accurate the prediction becomes.

3Ô∏è‚É£ **Click 'Predict'**  
You'll instantly know if the news is **REAL üì∞** or **FAKE ‚ö†Ô∏è**.

---

### üí° Tips for best accuracy:
- Avoid short texts.
- Provide full article when possible.
- Add a trusted source if available.

Enjoy using the app! üòÑ
""")

# -------------------------
# Main Title
# -------------------------
st.markdown("<h1 style='text-align: center; color:#4A90E2;'>üîç Fake News Detection</h1>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align: center; color: gray;'>Smart AI system to help you detect misinformation in seconds</h4>", unsafe_allow_html=True)

st.write("")

# -------------------------
# Input Section
# -------------------------
st.markdown("### üè∑Ô∏è News Source")
source = st.text_input(
    label=" ",                # ‚Üê label fix
    placeholder="Examples: Reuters, BBC, New York Times...",
    label_visibility="collapsed"
)

st.markdown("### ‚úçÔ∏è News Text")
text = st.text_area(
    label=" ",                # ‚Üê label fix
    placeholder="Paste the news text here...",
    height=230,
    label_visibility="collapsed"
)

# -------------------------
# Preprocessing function
# -------------------------
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = text.lower().strip()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    tokens = word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens)

# -------------------------
# Prediction function
# -------------------------
def predict(text, source=""):
    combined_text = f"{source} {text}" if source else text
    processed = preprocess_text(combined_text)
    vectorized = tfidvect.transform([processed])
    prediction = model.predict(vectorized)[0]  # 1=FAKE, 0=REAL
    return 'FAKE ‚ö†Ô∏è' if prediction == 1 else 'REAL üì∞'

# -------------------------
# Predict Button
# -------------------------
st.write("")
predict_btn = st.button("üîÆ Predict Now")

if predict_btn:
    if not text.strip():
        st.warning("‚ö†Ô∏è Please enter some news text first!")
    else:
        result = predict(text, source)

        if "FAKE" in result:
            st.error(f"### üö® Prediction: {result}")
        else:
            st.success(f"### ‚úÖ Prediction: {result}")
